name: real_image


camera_obs_latency: 0.0
robot_obs_latency: 0.0
gripper_obs_latency: 0.00
dataset_frequeny: 20 #59.94
obs_down_sample_steps: 0 # 3, 1


low_dim_obs_horizon: 2
img_obs_horizon: 2
action_horizon: 16

image_shape: [3, 224, 224]
dataset_path: /viscam/projects/kdm/dp_data/place_in_sink_4_condition_zero_action.zip
pose_repr: &pose_repr
  obs_pose_repr: relative # abs or rel
  action_pose_repr: relative # abs or rel or delta

shape_meta: &shape_meta
  # acceptable types: rgb, low_dim
  obs:

    # camera observations
    camera_stream_0:
      shape: ${task.image_shape}
      horizon: ${task.img_obs_horizon} # int
      latency_steps: 0 # float
      down_sample_steps: ${task.obs_down_sample_steps} # int
      type: rgb
    camera_stream_1:
      shape: ${task.image_shape}
      horizon: ${task.img_obs_horizon} # int
      latency_steps: 0 # float
      down_sample_steps: ${task.obs_down_sample_steps} # int
      type: rgb
    camera_stream_2:
      shape: ${task.image_shape}
      horizon: ${task.img_obs_horizon} # int
      latency_steps: 0 # float
      down_sample_steps: ${task.obs_down_sample_steps} # int
      type: rgb
    camera_stream_3:
      shape: ${task.image_shape}
      horizon: ${task.img_obs_horizon} # int
      latency_steps: 0 # float
      down_sample_steps: ${task.obs_down_sample_steps} # int
      type: rgb
    camera_stream_gripper:
      shape: ${task.image_shape}
      horizon: ${task.img_obs_horizon} # int
      latency_steps: 0 # float
      down_sample_steps: ${task.obs_down_sample_steps} # int
      type: rgb

    # robot action
    robot0_eef_pos:
      shape: [3]
      horizon: ${task.low_dim_obs_horizon} # int
      latency_steps: ${eval:'(${task.camera_obs_latency} - ${task.robot_obs_latency}) * ${task.dataset_frequeny}'} # float
      down_sample_steps: ${task.obs_down_sample_steps} # float
      type: low_dim
    robot0_eef_rot_6d:
      shape: [6]
      horizon: ${task.low_dim_obs_horizon} # int
      latency_steps: ${eval:'(${task.camera_obs_latency} - ${task.robot_obs_latency}) * ${task.dataset_frequeny}'} # float
      down_sample_steps: ${task.obs_down_sample_steps} # float
      type: low_dim
      rotation_rep: rotation_6d
    robot0_gripper_width:
      shape: [1]
      horizon: ${task.low_dim_obs_horizon} # int
      latency_steps: ${eval:'(${task.camera_obs_latency} - ${task.robot_obs_latency}) * ${task.dataset_frequeny}'} # float
      down_sample_steps: ${task.obs_down_sample_steps} # float
      type: low_dim

  action:
    horizon: ${task.action_horizon}
    latency_steps: 0 # float
    down_sample_steps: ${task.obs_down_sample_steps} # int
    shape: [10]
    rotation_rep: rotation_6d

env_runner:
  _target_: diffusion_policy.env_runner.real_pusht_image_runner.RealPushTImageRunner

dataset:
  _target_: diffusion_policy.dataset.umi_dataset.KDMImageDataset
  shape_meta: *shape_meta
  dataset_path: ${task.dataset_path}
  pose_repr: *pose_repr
  horizon: ${horizon}
  pad_before: ${eval:'${n_obs_steps}-1+${n_latency_steps}'}
  pad_after: ${eval:'${n_action_steps}-1'}
  n_obs_steps: ${dataset_obs_steps}
  n_latency_steps: ${n_latency_steps}
  use_cache: False
  seed: 42
  val_ratio: 0.00
  max_train_episodes: null
  delta_action: False
